"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6140],{9208:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>d,toc:()=>o});var i=t(7624),s=t(2172);const a={},r="MovieLens Recomendation Engine",d={id:"e2e-examples/movies",title:"MovieLens Recomendation Engine",description:"Introduction",source:"@site/docs/e2e-examples/movies.md",sourceDirName:"e2e-examples",slug:"/e2e-examples/movies",permalink:"/docs/docs/e2e-examples/movies",draft:!1,unlisted:!1,editUrl:"https://github.com/nodesteram-proj/docs/tree/main/packages/create-docusaurus/templates/shared/docs/e2e-examples/movies.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"End-to-End Examples",permalink:"/docs/docs/category/end-to-end-examples"},next:{title:"Official Plugins",permalink:"/docs/docs/category/official-plugins"}},l={},o=[{value:"Introduction",id:"introduction",level:2},{value:"Data",id:"data",level:2},{value:"<code>ratings.csv</code>",id:"ratingscsv",level:3},{value:"<code>movies.csv</code>",id:"moviescsv",level:3},{value:"<code>tags.csv</code>",id:"tagscsv",level:3},{value:"Getting Started",id:"getting-started",level:2},{value:"Building the Piplines",id:"building-the-piplines",level:2},{value:"Ratings",id:"ratings",level:3},{value:"Movies",id:"movies",level:3},{value:"Tags",id:"tags",level:3},{value:"Verifying the Data",id:"verifying-the-data",level:2},{value:"Conclusion",id:"conclusion",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",mermaid:"mermaid",p:"p",pre:"pre",ul:"ul",...(0,s.M)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"movielens-recomendation-engine",children:"MovieLens Recomendation Engine"}),"\n",(0,i.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(n.p,{children:"The MovieLens data set is a classic data set used for recommendation systems.\nIt contains a set of ratings given by a set of users to a set of movies.\nThe data set is available in different sizes, and we will use the smallest one, which contains 100,000 ratings."}),"\n",(0,i.jsx)(n.h2,{id:"data",children:"Data"}),"\n",(0,i.jsxs)(n.p,{children:["The data is available ",(0,i.jsx)(n.a,{href:"https://grouplens.org/datasets/movielens/100k/",children:"here"})," as a zip file.\nWhen you unzip it, you will find 3 csv files: ",(0,i.jsx)(n.code,{children:"ratings.csv"}),", ",(0,i.jsx)(n.code,{children:"movies.csv"}),", and ",(0,i.jsx)(n.code,{children:"tags.csv"}),".\nWe'll ingest all three of these files into our graph."]}),"\n",(0,i.jsx)(n.h3,{id:"ratingscsv",children:(0,i.jsx)(n.code,{children:"ratings.csv"})}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"ratings.csv"})," file contains the following columns:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"userId"}),": the id of the user who rated the movie (an integer)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"movieId"}),": the id of the movie that was rated (an integer)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"rating"}),": the rating given by the user (a float)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"timestamp"}),": the time when the rating was given (an integer)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"moviescsv",children:(0,i.jsx)(n.code,{children:"movies.csv"})}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"movies.csv"})," file contains the following columns:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"movieId"}),": the id of the movie (an integer)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"title"}),": the title of the movie (a string)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"genres"}),": the genres of the movie (a string), separated by ",(0,i.jsx)(n.code,{children:"|"})]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"tagscsv",children:(0,i.jsx)(n.code,{children:"tags.csv"})}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.code,{children:"tags.csv"})," file contains the following columns:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"userId"}),": the id of the user who tagged the movie (an integer)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"movieId"}),": the id of the movie that was tagged (an integer)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"tag"}),": the tag given by the user (a string)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"timestamp"}),": the time when the tag was given (an integer)"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,i.jsx)(n.p,{children:"First, we need to create a new nodestream project:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"nodestream new movies\nnodestream remove default sample # remove the default sample pipeline\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Then, we'll copy the data files into a newly ",(0,i.jsx)(n.code,{children:"data"})," directory of our project."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"mkdir -p movies/data\ncp path/to/ratings.csv path/to/movies.csv path/to/tags.csv movies/data\n"})}),"\n",(0,i.jsx)(n.p,{children:"Now we can cd into the project and scaffold the pipelines for each file:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd movies\nnodestream scaffold ratings\nnodestream scaffold movies\nnodestream scaffold tags\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This will create a new pipeline for each file, and we can now edit the ",(0,i.jsx)(n.code,{children:"ratings"})," pipeline to ingest the ",(0,i.jsx)(n.code,{children:"ratings.csv"})," file.\nBefore continuing, be sure to configure your database connection in the ",(0,i.jsx)(n.code,{children:"nodestream.yaml"})," file.\nSee the ",(0,i.jsx)(n.a,{href:"../../category/database-support",children:"Databases"})," section for more information."]}),"\n",(0,i.jsx)(n.h2,{id:"building-the-piplines",children:"Building the Piplines"}),"\n",(0,i.jsx)(n.p,{children:"In this example, we'll build a graph with the following schema:"}),"\n",(0,i.jsx)(n.mermaid,{value:"graph TD\n    A[User] --\x3e|rated| B(Movie)\n    B--\x3e|has| D[Genre]\n    G[User] --\x3e|tagged| C[Tag]\n    C --\x3e|applied to| B"}),"\n",(0,i.jsx)(n.h3,{id:"ratings",children:"Ratings"}),"\n",(0,i.jsxs)(n.p,{children:["We'll start by editing the ",(0,i.jsx)(n.code,{children:"ratings"})," pipeline to ingest the ",(0,i.jsx)(n.code,{children:"ratings.csv"})," file.\nOpen the ",(0,i.jsx)(n.code,{children:"pipelines/ratings.yaml"})," file and delete the default content.\nThen, add the following content:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"- implementation: nodestream.pipeline.extractors:FileExtractor\n  arguments:\n    globs:\n      - data/ratings.csv\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This will tell the pipeline to extract the data from the ",(0,i.jsx)(n.code,{children:"ratings.csv"})," file.\nHowever, this does not tell the pipeline how to ingest the data into the graph.\nWe'll need to add a new step to the pipeline to do that."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# ... previous content\n\n- implementation: nodestream.interpreting:Interpreter\n  arguments:\n    interpretations:\n      - type: source_node\n        node_type: User\n        key:\n          id: !jmespath userId\n      - type: relationship\n        relationship_type: RATED\n        node_type: Movie\n        node_key:\n          id: !jmespath movieId\n        relationship_properties:\n          rating: !jmespath rating\n          at: !jmespath timestamp\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This will tell the pipeline to interpret the data and create the ",(0,i.jsx)(n.code,{children:"User"})," and ",(0,i.jsx)(n.code,{children:"Movie"})," nodes, and the ",(0,i.jsx)(n.code,{children:"RATED"})," relationships between them.\nThe ",(0,i.jsx)(n.code,{children:"!jmespath"})," expressions are used to extract the data from the csv file.\nIn this case, we are extracting the ",(0,i.jsx)(n.code,{children:"userId"}),", ",(0,i.jsx)(n.code,{children:"movieId"}),", ",(0,i.jsx)(n.code,{children:"rating"}),", and ",(0,i.jsx)(n.code,{children:"timestamp"})," columns."]}),"\n",(0,i.jsxs)(n.p,{children:["Now, that we have the ",(0,i.jsx)(n.code,{children:"ratings"})," pipeline ready, we can generate the migrations and run the pipeline:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"nodestream migrations make\nnodestream migrations run -t my-db\nnodestream run movies -t my-db\n"})}),"\n",(0,i.jsx)(n.h3,{id:"movies",children:"Movies"}),"\n",(0,i.jsxs)(n.p,{children:["We'll do the same for the ",(0,i.jsx)(n.code,{children:"movies"})," pipeline.\nOpen the ",(0,i.jsx)(n.code,{children:"pipelines/movies.yaml"})," file and delete the default content.\nThen, add the following content:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"- implementation: nodestream.pipeline.extractors:FileExtractor\n  arguments:\n    globs:\n      - data/movies.csv\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This will tell the pipeline to extract the data from the ",(0,i.jsx)(n.code,{children:"movies.csv"})," file.\nWe'll need to add a new step to the pipeline to ingest the data into the graph."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# ... previous content\n\n- implementation: nodestream.interpreting:Interpreter\n  arguments:\n    interpretations:\n      - type: source_node\n        node_type: Movie\n        key:\n          id: !jmespath movieId\n        properties:\n          title: !jmespath title\n      - type: relationship\n        relationship_type: HAS_GENRE\n        node_type: Genre\n        find_many: true\n        node_key:\n          id: !split \n            data: !jmespath genres\n            delimiter: '|'\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This will tell the pipeline to interpret the data and create the ",(0,i.jsx)(n.code,{children:"Movie"})," nodes.\nThe ",(0,i.jsx)(n.code,{children:"!jmespath"})," expressions are used to extract the data from the csv file.\nNow, that we have the ",(0,i.jsx)(n.code,{children:"movies"})," pipeline ready, we can generate the migrations and run the pipeline:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"nodestream migrations make\nnodestream migrations run -t my-db\nnodestream run movies -t my-db\n"})}),"\n",(0,i.jsx)(n.h3,{id:"tags",children:"Tags"}),"\n",(0,i.jsxs)(n.p,{children:["We'll do the same for the ",(0,i.jsx)(n.code,{children:"tags"})," pipeline.\nOpen the ",(0,i.jsx)(n.code,{children:"pipelines/tags.yaml"})," file and delete the default content.\nThen, add the following content:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"- implementation: nodestream.pipeline.extractors:FileExtractor\n  argumenets:\n    globs:\n      - data/tags.csv\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This will tell the pipeline to extract the data from the ",(0,i.jsx)(n.code,{children:"tags.csv"})," file.\nWe'll need to add a new step to the pipeline to ingest the data into the graph."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:"# ... previous content\n\n- implementation: nodestream.interpreting:Interpreter\n  arguments:\n    interpretations:\n      - type: source_node\n        node_type: Tag\n        key:\n          value: !jmespath tag\n      - type: relationship\n        relationship_type: TAGGED\n        node_type: User\n        node_key:\n          id: !jmespath userId\n        relationship_properties:\n          at: !jmespath timestamp\n        outbound: false\n      - type: relationship\n        relationship_type: APPLIED_TO\n        node_type: Movie\n        node_key:\n          id: !jmespath movieId\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This will tell the pipeline to interpret the data and create the ",(0,i.jsx)(n.code,{children:"Tag"})," nodes, and the ",(0,i.jsx)(n.code,{children:"TAGGED"})," and ",(0,i.jsx)(n.code,{children:"APPLIED_TO"})," relationships between them.\nThe ",(0,i.jsx)(n.code,{children:"!jmespath"})," expressions are used to extract the data from the csv file.\nNow, that we have the ",(0,i.jsx)(n.code,{children:"tags"})," pipeline ready, we can generate the migrations and run the pipeline:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"nodestream migrations make\nnodestream migrations run -t my-db\nnodestream run movies -t my-db\n"})}),"\n",(0,i.jsx)(n.h2,{id:"verifying-the-data",children:"Verifying the Data"}),"\n",(0,i.jsx)(n.p,{children:"We can now verify that the data was ingested into the graph by running some queries."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cypher",children:"MATCH (u:User)-[r:RATED]->(m:Movie)\nRETURN u, r, m\nLIMIT 10\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cypher",children:"MATCH (m:Movie)-[t:TAGGED]->(t:Tag)\nRETURN m, t\nLIMIT 10\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cypher",children:"MATCH (m:Movie)\nRETURN m\nLIMIT 10\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cypher",children:"MATCH (u:User)\nRETURN u\nLIMIT 10\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cypher",children:"MATCH (t:Tag)\nRETURN t\nLIMIT 10\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cypher",children:"MATCH (g:Genre)\nRETURN g\nLIMIT 10\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cypher",children:"MATCH (u:User)-[r:RATED]->(m:Movie)-[:HAS]->(g:Genre)\nRETURN u, r, m, g\nLIMIT 10\n"})}),"\n",(0,i.jsx)(n.p,{children:"This should return some data from the graph, showing that the data was ingested correctly."}),"\n",(0,i.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,i.jsx)(n.p,{children:"Success \ud83c\udf89!"}),"\n",(0,i.jsxs)(n.p,{children:["Now that we have the data ingested into the graph, we can start building recommendation algorithms.\nWe can use the ",(0,i.jsx)(n.code,{children:"ratings"})," and ",(0,i.jsx)(n.code,{children:"tags"})," data to build a collaborative filtering algorithm, and the ",(0,i.jsx)(n.code,{children:"genres"})," data to build a content-based filtering algorithm.\nWe can also use the ",(0,i.jsx)(n.code,{children:"movies"})," data to build a graph-based recommendation algorithm."]})]})}function h(e={}){const{wrapper:n}={...(0,s.M)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},2172:(e,n,t)=>{t.d(n,{I:()=>d,M:()=>r});var i=t(1504);const s={},a=i.createContext(s);function r(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);